{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nfrom pyspark.ml.linalg import SparseVector, DenseVector\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml import Pipeline\n\nimport pandas as pd\nfrom autofeat import FeatureSelector, AutoFeatRegressor\n\n#Instantiate the spark session\nspark = SparkSession.builder.appName(\"Feature_Engineering\").getOrCreate()\n\nspark.conf.set(\"spark.sql.shuffle.partitions\", 8)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["#read csv file with aggregated data\ncyc_agg_DF = spark.read.csv(\"/FileStore/tables/agg_clean_DF.csv\", inferSchema = True, header = True).cache()\n\n#materialize the DF in memory\ncyc_agg_DF.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["cyc_agg_DF_pddf = cyc_agg_DF.toPandas()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["#get dummies for each cell_no\ncyc_agg_DF_pddf = pd.get_dummies(cyc_agg_DF_pddf, prefix=['cell'], columns = ['cell_no'])\n\ncyc_agg_DF_pddf.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>protocol</th>\n      <th>cycle</th>\n      <th>di</th>\n      <th>dur_by_ocv</th>\n      <th>min_ocv</th>\n      <th>max_ocv</th>\n      <th>rng_ocv</th>\n      <th>charge_duration</th>\n      <th>i0x91</th>\n      <th>i0x2</th>\n      <th>i0xcd</th>\n      <th>i0x28</th>\n      <th>i0xb1</th>\n      <th>i0x83</th>\n      <th>i0x8c</th>\n      <th>i0x6</th>\n      <th>i0xa7</th>\n      <th>i0x2a</th>\n      <th>i0x8a</th>\n      <th>i0x94</th>\n      <th>i0x73</th>\n      <th>B_65</th>\n      <th>B_78</th>\n      <th>T_5a</th>\n      <th>T_b6</th>\n      <th>c_const_B_2d</th>\n      <th>c_const_T_c4</th>\n      <th>c_const_B_81</th>\n      <th>c_const_B_40</th>\n      <th>c_const_T_32</th>\n      <th>c_const_T_bc</th>\n      <th>c_const_B_6b</th>\n      <th>c_const_B_9</th>\n      <th>c_const_B_3b</th>\n      <th>c_const_B_c9</th>\n      <th>c_const_B_b2</th>\n      <th>c_const_B_14</th>\n      <th>c_const_B_76</th>\n      <th>c_const_B_29</th>\n      <th>c_const_T_5</th>\n      <th>P_const_30</th>\n      <th>P_const_9f</th>\n      <th>P_const_2c</th>\n      <th>cell_1</th>\n      <th>cell_3</th>\n      <th>cell_4</th>\n      <th>cell_5</th>\n      <th>cell_6</th>\n      <th>cell_7</th>\n      <th>cell_9</th>\n      <th>cell_10</th>\n      <th>cell_11</th>\n      <th>cell_13</th>\n      <th>cell_14</th>\n      <th>cell_18</th>\n      <th>cell_19</th>\n      <th>cell_20</th>\n      <th>cell_23</th>\n      <th>cell_24</th>\n      <th>cell_26</th>\n      <th>cell_27</th>\n      <th>cell_28</th>\n      <th>cell_29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>4</td>\n      <td>0.858171</td>\n      <td>2.583579</td>\n      <td>3329.0</td>\n      <td>4223.0</td>\n      <td>894.0</td>\n      <td>2309.719999</td>\n      <td>0.434783</td>\n      <td>0.599933</td>\n      <td>0.000000</td>\n      <td>0.851064</td>\n      <td>0.249766</td>\n      <td>0.653333</td>\n      <td>0.521605</td>\n      <td>1.0</td>\n      <td>0.084746</td>\n      <td>0.899833</td>\n      <td>0.253061</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.090909</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>5</td>\n      <td>0.837832</td>\n      <td>2.456929</td>\n      <td>3439.0</td>\n      <td>4231.0</td>\n      <td>792.0</td>\n      <td>1945.888000</td>\n      <td>0.434783</td>\n      <td>0.599933</td>\n      <td>0.024512</td>\n      <td>0.851064</td>\n      <td>0.249766</td>\n      <td>0.655652</td>\n      <td>0.530193</td>\n      <td>1.0</td>\n      <td>0.084746</td>\n      <td>0.882413</td>\n      <td>0.253061</td>\n      <td>0.016339</td>\n      <td>0.019608</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.090909</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>6</td>\n      <td>0.695297</td>\n      <td>2.940633</td>\n      <td>3420.0</td>\n      <td>4221.0</td>\n      <td>801.0</td>\n      <td>2355.447000</td>\n      <td>0.434783</td>\n      <td>0.599933</td>\n      <td>0.004502</td>\n      <td>0.851064</td>\n      <td>0.249766</td>\n      <td>0.717538</td>\n      <td>0.759402</td>\n      <td>1.0</td>\n      <td>0.084746</td>\n      <td>0.374342</td>\n      <td>0.092182</td>\n      <td>0.003001</td>\n      <td>0.003601</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.090909</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>7</td>\n      <td>0.693164</td>\n      <td>2.945015</td>\n      <td>3419.0</td>\n      <td>4221.0</td>\n      <td>802.0</td>\n      <td>2361.902001</td>\n      <td>0.434783</td>\n      <td>0.599933</td>\n      <td>0.009505</td>\n      <td>0.851064</td>\n      <td>0.249766</td>\n      <td>0.718182</td>\n      <td>0.761785</td>\n      <td>1.0</td>\n      <td>0.084746</td>\n      <td>0.369151</td>\n      <td>0.090847</td>\n      <td>0.006335</td>\n      <td>0.007603</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.090909</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>8</td>\n      <td>0.702145</td>\n      <td>2.903154</td>\n      <td>3422.0</td>\n      <td>4220.0</td>\n      <td>798.0</td>\n      <td>2316.717000</td>\n      <td>0.434783</td>\n      <td>0.599933</td>\n      <td>0.019510</td>\n      <td>0.851064</td>\n      <td>0.249766</td>\n      <td>0.713220</td>\n      <td>0.743409</td>\n      <td>1.0</td>\n      <td>0.084746</td>\n      <td>0.409185</td>\n      <td>0.101141</td>\n      <td>0.013004</td>\n      <td>0.015606</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.090909</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["#model input\nX = cyc_agg_DF_pddf.drop(['protocol','di', 'charge_duration', 'dur_by_ocv', 'cell_1'], axis = 1 )\n\n#model outputs (di and dur_by_ocv)\nY_di = cyc_agg_DF_pddf['di']\nY_dur_by_ocv = cyc_agg_DF_pddf['dur_by_ocv']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["#Select the features to used for feature engineering (ignore dummies)\nfeat_use = [col for col in X.columns if not col.startswith('cell_')]\n\n#Select the features to keep during selection (dummies) \nfeat_keep = [col for col in X.columns if col.startswith('cell_')]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["print(feat_keep)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;cell_3&#39;, &#39;cell_4&#39;, &#39;cell_5&#39;, &#39;cell_6&#39;, &#39;cell_7&#39;, &#39;cell_9&#39;, &#39;cell_10&#39;, &#39;cell_11&#39;, &#39;cell_13&#39;, &#39;cell_14&#39;, &#39;cell_18&#39;, &#39;cell_19&#39;, &#39;cell_20&#39;, &#39;cell_23&#39;, &#39;cell_24&#39;, &#39;cell_26&#39;, &#39;cell_27&#39;, &#39;cell_28&#39;, &#39;cell_29&#39;]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["#create the autofeat model for regression\naf_regr_di = AutoFeatRegressor(feateng_cols = feat_use, \n                               feateng_steps= 2,\n                               transformations=(\"1/\", \"exp\", \"log\", \"abs\", \"sqrt\", \"^2\", \"^3\", \"1+\", \"1-\", \"sin\", \"cos\", \"exp-\", \"2^\"),\n                               verbose=1,\n                               n_jobs=6)\n\n#fit and transform X to obtain engineered features for di\nnew_df_di = af_regr_di.fit_transform(X, Y_di)\nr2_di = af_regr_di.score(X, Y_di)\nprint(\"## Final R^2: %.4f\" % r2_di)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[AutoFeat] The 2 step feature engineering process could generate up to 128778 features.\n[AutoFeat] With 8288 data points this new feature matrix would use about 4.27 gb of space.\n[feateng] Step 1: transformation of original features\n[feateng]               0/             39 features transformed\r[feateng] Generated 224 transformed features from 39 original features - done.\n[feateng] Step 2: first combination of features\n[feateng]               0/          34453 feature tuples combined\r[feateng]             100/          34453 feature tuples combined\r[feateng]             200/          34453 feature tuples combined\r[feateng]             300/          34453 feature tuples combined\r[feateng]             400/          34453 feature tuples combined\r[feateng]             500/          34453 feature tuples combined\r[feateng]             600/          34453 feature tuples combined\r[feateng]             700/          34453 feature tuples combined\r[feateng]             800/          34453 feature tuples combined\r[feateng]             900/          34453 feature tuples combined\r[feateng]            1000/          34453 feature tuples combined\r[feateng]            1100/          34453 feature tuples combined\r[feateng]            1200/          34453 feature tuples combined\r[feateng]            1300/          34453 feature tuples combined\r[feateng]            1400/          34453 feature tuples combined\r[feateng]            1500/          34453 feature tuples combined\r[feateng]            1600/          34453 feature tuples combined\r[feateng]            1700/          34453 feature tuples combined\r[feateng]            1800/          34453 feature tuples combined\r[feateng]            1900/          34453 feature tuples combined\r[feateng]            2000/          34453 feature tuples combined\r[feateng]            2100/          34453 feature tuples combined\r[feateng]            2200/          34453 feature tuples combined\r[feateng]            2300/          34453 feature tuples combined\r[feateng]            2400/          34453 feature tuples combined\r[feateng]            2500/          34453 feature tuples combined\r[feateng]            2600/          34453 feature tuples combined\r[feateng]            2700/          34453 feature tuples combined\r[feateng]            2800/          34453 feature tuples combined\r[feateng]            2900/          34453 feature tuples combined\r[feateng]            3000/          34453 feature tuples combined\r[feateng]            3100/          34453 feature tuples combined\r[feateng]            3200/          34453 feature tuples combined\r[feateng]            3300/          34453 feature tuples combined\r[feateng]            3400/          34453 feature tuples combined\r[feateng]            3500/          34453 feature tuples combined\r[feateng]            3600/          34453 feature tuples combined\r[feateng]            3700/          34453 feature tuples combined\r[feateng]            3800/          34453 feature tuples combined\r[feateng]            3900/          34453 feature tuples combined\r[feateng]            4000/          34453 feature tuples combined\r[feateng]            4100/          34453 feature tuples combined\r[feateng]            4200/          34453 feature tuples combined\r[feateng]            4300/          34453 feature tuples combined\r[feateng]            4400/          34453 feature tuples combined\r[feateng]            4500/          34453 feature tuples combined\r[feateng]            4600/          34453 feature tuples combined\r[feateng]            4700/          34453 feature tuples combined\r[feateng]            4800/          34453 feature tuples combined\r[feateng]            4900/          34453 feature tuples combined\r[feateng]            5000/          34453 feature tuples combined\r[feateng]            5100/          34453 feature tuples combined\r[feateng]            5200/          34453 feature tuples combined\r[feateng]            5300/          34453 feature tuples combined\r[feateng]            5400/          34453 feature tuples combined\r[feateng]            5500/          34453 feature tuples combined\r[feateng]            5600/          34453 feature tuples combined\r[feateng]            5700/          34453 feature tuples combined\r[feateng]            5800/          34453 feature tuples combined\r[feateng]            5900/          34453 feature tuples combined\r[feateng]            6000/          34453 feature tuples combined\r[feateng]            6100/          34453 feature tuples combined\r[feateng]            6200/          34453 feature tuples combined\r[feateng]            6300/          34453 feature tuples combined\r[feateng]            6400/          34453 feature tuples combined\r[feateng]            6500/          34453 feature tuples combined\r[feateng]            6600/          34453 feature tuples combined\r[feateng]            6700/          34453 feature tuples combined\r[feateng]            6800/          34453 feature tuples combined\r[feateng]            6900/          34453 feature tuples combined\r[feateng]            7000/          34453 feature tuples combined\r[feateng]            7100/          34453 feature tuples combined\r[feateng]            7200/          34453 feature tuples combined\r[feateng]            7300/          34453 feature tuples combined\r[feateng]            7400/          34453 feature tuples combined\r[feateng]            7500/          34453 feature tuples combined\r[feateng]            7600/          34453 feature tuples combined\r[feateng]            7700/          34453 feature tuples combined\r[feateng]            7800/          34453 feature tuples combined\r[feateng]            7900/          34453 feature tuples combined\r[feateng]            8000/          34453 feature tuples combined\r[feateng]            8100/          34453 feature tuples combined\r[feateng]            8200/          34453 feature tuples combined\r[feateng]            8300/          34453 feature tuples combined\r[feateng]            8400/          34453 feature tuples combined\r[feateng]            8500/          34453 feature tuples combined\r[feateng]            8600/          34453 feature tuples combined\r[feateng]            8700/          34453 feature tuples combined\r[feateng]            8800/          34453 feature tuples combined\r[feateng]            8900/          34453 feature tuples combined\r[feateng]            9000/          34453 feature tuples combined\r[feateng]            9100/          34453 feature tuples combined\r[feateng]            9200/          34453 feature tuples combined\r[feateng]            9300/          34453 feature tuples combined\r[feateng]            9400/          34453 feature tuples combined\r[feateng]            9500/          34453 feature tuples combined\r[feateng]            9600/          34453 feature tuples combined\r[feateng]            9700/          34453 feature tuples combined\r[feateng]            9800/          34453 feature tuples combined\r[feateng]            9900/          34453 feature tuples combined\r[feateng]           10000/          34453 feature tuples combined\r[feateng]           10100/          34453 feature tuples combined\r[feateng]           10200/          34453 feature tuples combined\r[feateng]           10300/          34453 feature tuples combined\r/databricks/python/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n  x = um.multiply(x, x, out=x)\n/databricks/python/lib/python3.7/site-packages/numpy/core/_methods.py:199: RuntimeWarning: overflow encountered in reduce\n  ret = umr_sum(x, axis, dtype, out, keepdims)\n[feateng]           10400/          34453 feature tuples combined\r[feateng]           10500/          34453 feature tuples combined\r[feateng]           10600/          34453 feature tuples combined\r[feateng]           10700/          34453 feature tuples combined\r[feateng]           10800/          34453 feature tuples combined\r[feateng]           10900/          34453 feature tuples combined\r[feateng]           11000/          34453 feature tuples combined\r[feateng]           11100/          34453 feature tuples combined\r[feateng]           11200/          34453 feature tuples combined\r[feateng]           11300/          34453 feature tuples combined\r[feateng]           11400/          34453 feature tuples combined\r[feateng]           11500/          34453 feature tuples combined\r[feateng]           11600/          34453 feature tuples combined\r[feateng]           11700/          34453 feature tuples combined\r[feateng]           11800/          34453 feature tuples combined\r[feateng]           11900/          34453 feature tuples combined\r[feateng]           12000/          34453 feature tuples combined\r[feateng]           12100/          34453 feature tuples combined\r[feateng]           12200/          34453 feature tuples combined\r[feateng]           12300/          34453 feature tuples combined\r[feateng]           12400/          34453 feature tuples combined\r[feateng]           12500/          34453 feature tuples combined\r[feateng]           12600/          34453 feature tuples combined\r[feateng]           12700/          34453 feature tuples combined\r[feateng]           12800/          34453 feature tuples combined\r[feateng]           12900/          34453 feature tuples combined\r[feateng]           13000/          34453 feature tuples combined\r[feateng]           13100/          34453 feature tuples combined\r[feateng]           13200/          34453 feature tuples combined\r[feateng]           13300/          34453 feature tuples combined\r[feateng]           13400/          34453 feature tuples combined\r[feateng]           13500/          34453 feature tuples combined\r[feateng]           13600/          34453 feature tuples combined\r[feateng]           13700/          34453 feature tuples combined\r[feateng]           13800/          34453 feature tuples combined\r[feateng]           13900/          34453 feature tuples combined\r[feateng]           14000/          34453 feature tuples combined\r[feateng]           14100/          34453 feature tuples combined\r[feateng]           14200/          34453 feature tuples combined\r[feateng]           14300/          34453 feature tuples combined\r[feateng]           14400/          34453 feature tuples combined\r[feateng]           14500/          34453 feature tuples combined\r[feateng]           14600/          34453 feature tuples combined\r[feateng]           14700/          34453 feature tuples combined\r[feateng]           14800/          34453 feature tuples combined\r[feateng]           14900/          34453 feature tuples combined\r[feateng]           15000/          34453 feature tuples combined\r[feateng]           15100/          34453 feature tuples combined\r[feateng]           15200/          34453 feature tuples combined\r[feateng]           15300/          34453 feature tuples combined\r[feateng]           15400/          34453 feature tuples combined\r[feateng]           15500/          34453 feature tuples combined\r[feateng]           15600/          34453 feature tuples combined\r[feateng]           15700/          34453 feature tuples combined\r[feateng]           15800/          34453 feature tuples combined\r[feateng]           15900/          34453 feature tuples combined\r[feateng]           16000/          34453 feature tuples combined\r[feateng]           16100/          34453 feature tuples combined\r[feateng]           16200/          34453 feature tuples combined\r[feateng]           16300/          34453 feature tuples combined\r[feateng]           16400/          34453 feature tuples combined\r[feateng]           16500/          34453 feature tuples combined\r[feateng]           16600/          34453 feature tuples combined\r[feateng]           16700/          34453 feature tuples combined\r[feateng]           16800/          34453 feature tuples combined\r[feateng]           16900/          34453 feature tuples combined\r[feateng]           17000/          34453 feature tuples combined\r[feateng]           17100/          34453 feature tuples combined\r[feateng]           17200/          34453 feature tuples combined\r[feateng]           17300/          34453 feature tuples combined\r[feateng]           17400/          34453 feature tuples combined\r[feateng]           17500/          34453 feature tuples combined\r[feateng]           17600/          34453 feature tuples combined\r[feateng]           17700/          34453 feature tuples combined\r[feateng]           17800/          34453 feature tuples combined\r[feateng]           17900/          34453 feature tuples combined\r[feateng]           18000/          34453 feature tuples combined\r[feateng]           18100/          34453 feature tuples combined\r[feateng]           18200/          34453 feature tuples combined\r[feateng]           18300/          34453 feature tuples combined\r[feateng]           18400/          34453 feature tuples combined\r[feateng]           18500/          34453 feature tuples combined\r[feateng]           18600/          34453 feature tuples combined\r[feateng]           18700/          34453 feature tuples combined\r[feateng]           18800/          34453 feature tuples combined\r[feateng]           18900/          34453 feature tuples combined\r[feateng]           19000/          34453 feature tuples combined\r[feateng]           19100/          34453 feature tuples combined\r[feateng]           19200/          34453 feature tuples combined\r[feateng]           19300/          34453 feature tuples combined\r[feateng]           19400/          34453 feature tuples combined\r[feateng]           19500/          34453 feature tuples combined\r[feateng]           19600/          34453 feature tuples combined\r[feateng]           19700/          34453 feature tuples combined\r[feateng]           19800/          34453 feature tuples combined\r[feateng]           19900/          34453 feature tuples combined\r[feateng]           20000/          34453 feature tuples combined\r[feateng]           20100/          34453 feature tuples combined\r[feateng]           20200/          34453 feature tuples combined\r[feateng]           20300/          34453 feature tuples combined\r[feateng]           20400/          34453 feature tuples combined\r[feateng]           20500/          34453 feature tuples combined\r[feateng]           20600/          34453 feature tuples combined\r[feateng]           20700/          34453 feature tuples combined\r[feateng]           20800/          34453 feature tuples combined\r[feateng]           20900/          34453 feature tuples combined\r[feateng]           21000/          34453 feature tuples combined\r[feateng]           21100/          34453 feature tuples combined\r[feateng]           21200/          34453 feature tuples combined\r[feateng]           21300/          34453 feature tuples combined\r[feateng]           21400/          34453 feature tuples combined\r[feateng]           21500/          34453 feature tuples combined\r[feateng]           21600/          34453 feature tuples combined\r[feateng]           21700/          34453 feature tuples combined\r[feateng]           21800/          34453 feature tuples combined\r[feateng]           21900/          34453 feature tuples combined\r[feateng]           22000/          34453 feature tuples combined\r[feateng]           22100/          34453 feature tuples combined\r[feateng]           22200/          34453 feature tuples combined\r[feateng]           22300/          34453 feature tuples combined\r[feateng]           22400/          34453 feature tuples combined\r[feateng]           22500/          34453 feature tuples combined\r[feateng]           22600/          34453 feature tuples combined\r[feateng]           22700/          34453 feature tuples combined\r[feateng]           22800/          34453 feature tuples combined\r[feateng]           22900/          34453 feature tuples combined\r[feateng]           23000/          34453 feature tuples combined\r[feateng]           23100/          34453 feature tuples combined\r[feateng]           23200/          34453 feature tuples combined\r[feateng]           23300/          34453 feature tuples combined\r[feateng]           23400/          34453 feature tuples combined\r[feateng]           23500/          34453 feature tuples combined\r[feateng]           23600/          34453 feature tuples combined\r[feateng]           23700/          34453 feature tuples combined\r[feateng]           23800/          34453 feature tuples combined\r[feateng]           23900/          34453 feature tuples combined\r[feateng]           24000/          34453 feature tuples combined\r[feateng]           24100/          34453 feature tuples combined\r[feateng]           24200/          34453 feature tuples combined\r[feateng]           24300/          34453 feature tuples combined\r[feateng]           24400/          34453 feature tuples combined\r[feateng]           24500/          34453 feature tuples combined\r[feateng]           24600/          34453 feature tuples combined\r[feateng]           24700/          34453 feature tuples combined\r[feateng]           24800/          34453 feature tuples combined\r[feateng]           24900/          34453 feature tuples combined\r[feateng]           25000/          34453 feature tuples combined\r[feateng]           25100/          34453 feature tuples combined\r[feateng]           25200/          34453 feature tuples combined\r[feateng]           25300/          34453 feature tuples combined\r[feateng]           25400/          34453 feature tuples combined\r[feateng]           25500/          34453 feature tuples combined\r[feateng]           25600/          34453 feature tuples combined\r[feateng]           25700/          34453 feature tuples combined\r[feateng]           25800/          34453 feature tuples combined\r[feateng]           25900/          34453 feature tuples combined\r[feateng]           26000/          34453 feature tuples combined\r[feateng]           26100/          34453 feature tuples combined\r[feateng]           26200/          34453 feature tuples combined\r[feateng]           26300/          34453 feature tuples combined\r[feateng]           26400/          34453 feature tuples combined\r[feateng]           26500/          34453 feature tuples combined\r[feateng]           26600/          34453 feature tuples combined\r[feateng]           26700/          34453 feature tuples combined\r[feateng]           26800/          34453 feature tuples combined\r[feateng]           26900/          34453 feature tuples combined\r[feateng]           27000/          34453 feature tuples combined\r[feateng]           27100/          34453 feature tuples combined\r[feateng]           27200/          34453 feature tuples combined\r[feateng]           27300/          34453 feature tuples combined\r[feateng]           27400/          34453 feature tuples combined\r[feateng]           27500/          34453 feature tuples combined\r[feateng]           27600/          34453 feature tuples combined\r[feateng]           27700/          34453 feature tuples combined\r[feateng]           27800/          34453 feature tuples combined\r[feateng]           27900/          34453 feature tuples combined\r[feateng]           28000/          34453 feature tuples combined\r[feateng]           28100/          34453 feature tuples combined\r[feateng]           28200/          34453 feature tuples combined\r[feateng]           28300/          34453 feature tuples combined\r[feateng]           28400/          34453 feature tuples combined\r[feateng]           28500/          34453 feature tuples combined\r[feateng]           28600/          34453 feature tuples combined\r[feateng]           28700/          34453 feature tuples combined\r[feateng]           28800/          34453 feature tuples combined\r[feateng]           28900/          34453 feature tuples combined\r[feateng]           29000/          34453 feature tuples combined\r[feateng]           29100/          34453 feature tuples combined\r[feateng]           29200/          34453 feature tuples combined\r[feateng]           29300/          34453 feature tuples combined\r[feateng]           29400/          34453 feature tuples combined\r[feateng]           29500/          34453 feature tuples combined\r[feateng]           29600/          34453 feature tuples combined\r[feateng]           29700/          34453 feature tuples combined\r[feateng]           29800/          34453 feature tuples combined\r[feateng]           29900/          34453 feature tuples combined\r[feateng]           30000/          34453 feature tuples combined\r[feateng]           30100/          34453 feature tuples combined\r[feateng]           30200/          34453 feature tuples combined\r[feateng]           30300/          34453 feature tuples combined\r[feateng]           30400/          34453 feature tuples combined\r[feateng]           30500/          34453 feature tuples combined\r[feateng]           30600/          34453 feature tuples combined\r[feateng]           30700/          34453 feature tuples combined\r[feateng]           30800/          34453 feature tuples combined\r[feateng]           30900/          34453 feature tuples combined\r[feateng]           31000/          34453 feature tuples combined\r[feateng]           31100/          34453 feature tuples combined\r[feateng]           31200/          34453 feature tuples combined\r[feateng]           31300/          34453 feature tuples combined\r[feateng]           31400/          34453 feature tuples combined\r[feateng]           31500/          34453 feature tuples combined\r[feateng]           31600/          34453 feature tuples combined\r[feateng]           31700/          34453 feature tuples combined\r[feateng]           31800/          34453 feature tuples combined\r[feateng]           31900/          34453 feature tuples combined\r[feateng]           32000/          34453 feature tuples combined\r[feateng]           32100/          34453 feature tuples combined\r[feateng]           32200/          34453 feature tuples combined\r[feateng]           32300/          34453 feature tuples combined\r[feateng]           32400/          34453 feature tuples combined\r[feateng]           32500/          34453 feature tuples combined\r[feateng]           32600/          34453 feature tuples combined\r[feateng]           32700/          34453 feature tuples combined\r[feateng]           32800/          34453 feature tuples combined\r[feateng]           32900/          34453 feature tuples combined\r[feateng]           33000/          34453 feature tuples combined\r[feateng]           33100/          34453 feature tuples combined\r[feateng]           33200/          34453 feature tuples combined\r[feateng]           33300/          34453 feature tuples combined\r[feateng]           33400/          34453 feature tuples combined\r[feateng]           33500/          34453 feature tuples combined\r[feateng]           33600/          34453 feature tuples combined\r[feateng]           33700/          34453 feature tuples combined\r[feateng]           33800/          34453 feature tuples combined\r[feateng]           33900/          34453 feature tuples combined\r[feateng]           34000/          34453 feature tuples combined\r[feateng]           34100/          34453 feature tuples combined\r[feateng]           34200/          34453 feature tuples combined\r[feateng]           34300/          34453 feature tuples combined\r[feateng]           34400/          34453 feature tuples combined\r[feateng] Generated 33689 feature combinations from 34453 original feature tuples - done.\n[feateng] Generated altogether 34642 new features in 2 steps\n[feateng] Removing correlated features, as well as additions at the highest level\n/databricks/python/lib/python3.7/site-packages/sympy/__init__.py:676: SymPyDeprecationWarning: \n\nimporting sympy.core.add with &#39;from sympy import *&#39; has been\ndeprecated since SymPy 1.6. Use import sympy.core.add instead. See\nhttps://github.com/sympy/sympy/issues/18245 for more info.\n\n  deprecated_since_version=&#34;1.6&#34;).warn()\n[feateng] Generated a total of 12831 additional features\n[featsel] Scaling data...done.\n[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to new file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-733dc1b0b74a4492b7bb229fb84f9bd1.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-733dc1b0b74a4492b7bb229fb84f9bd1.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-733dc1b0b74a4492b7bb229fb84f9bd1.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-733dc1b0b74a4492b7bb229fb84f9bd1.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-733dc1b0b74a4492b7bb229fb84f9bd1.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\n[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed: 35.6min\n[Parallel(n_jobs=6)]: Done   2 out of   5 | elapsed: 53.9min remaining: 80.8min\n[Parallel(n_jobs=6)]: Done   3 out of   5 | elapsed: 57.3min remaining: 38.2min\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed: 59.7min remaining:    0.0s\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed: 59.7min finished\n[featsel] 183 features after 5 feature selection runs\n[featsel] 129 features after correlation filtering\n[featsel] 24 features after noise filtering\n[AutoFeat] Computing 22 new features.\n[AutoFeat]     0/   22 new features\r[AutoFeat]     1/   22 new features\r[AutoFeat]     2/   22 new features\r[AutoFeat]     3/   22 new features\r[AutoFeat]     4/   22 new features\r[AutoFeat]     5/   22 new features\r[AutoFeat]     6/   22 new features\r[AutoFeat]     7/   22 new features\r[AutoFeat]     8/   22 new features\r[AutoFeat]     9/   22 new features\r[AutoFeat]    10/   22 new features\r[AutoFeat]    11/   22 new features\r[AutoFeat]    12/   22 new features\r[AutoFeat]    13/   22 new features\r[AutoFeat]    14/   22 new features\r[AutoFeat]    15/   22 new features\r[AutoFeat]    16/   22 new features\r[AutoFeat]    17/   22 new features\r[AutoFeat]    18/   22 new features\r[AutoFeat]    19/   22 new features\r[AutoFeat]    20/   22 new features\r[AutoFeat]    21/   22 new features\r[AutoFeat]    22/   22 new features ...done.\n[AutoFeat] Final dataframe with 80 feature columns (22 new).\n[AutoFeat] Training final regression model.\n[AutoFeat] Trained model: largest coefficients:\n0.4825741909517403\n0.637263 * c_const_T_c4**3*i0x91**3\n0.298063 * c_const_T_32**2*i0x2a\n0.191834 * i0x28**3*sin(i0x8a)\n0.129159 * i0x8c**2*(1 - i0x8c)\n0.107998 * i0x28**3*sin(i0x2a)\n0.106089 * exp(i0x2a)*exp(-i0xa7)\n0.051267 * sqrt(i0xb1)*(1 - i0xb1)\n-0.040003 * (1 - i0x28)*sin(i0x28)\n0.038758 * sqrt(i0xa7)*cos(c_const_T_32)\n0.015025 * sqrt(i0x91)*(1 - i0x91)\n-0.014483 * c_const_B_b2*cos(i0x28)\n-0.014267 * sqrt(i0xa7)*exp(c_const_T_5)\n-0.013563 * cell_9\n-0.010609 * 2**B_78*exp(T_5a)\n0.003210 * exp(c_const_T_c4)*sin(i0x91)\n-0.002701 * i0x8c**2*(1 - T_5a)\n-0.000588 * cycle*i0x2a**2\n0.000046 * cycle*sin(i0x91)\n[AutoFeat] Final score: 0.9693\n[AutoFeat] Computing 22 new features.\n[AutoFeat]     0/   22 new features\r[AutoFeat]     1/   22 new features\r[AutoFeat]     2/   22 new features\r[AutoFeat]     3/   22 new features\r[AutoFeat]     4/   22 new features\r[AutoFeat]     5/   22 new features\r[AutoFeat]     6/   22 new features\r[AutoFeat]     7/   22 new features\r[AutoFeat]     8/   22 new features\r[AutoFeat]     9/   22 new features\r[AutoFeat]    10/   22 new features\r[AutoFeat]    11/   22 new features\r[AutoFeat]    12/   22 new features\r[AutoFeat]    13/   22 new features\r[AutoFeat]    14/   22 new features\r[AutoFeat]    15/   22 new features\r[AutoFeat]    16/   22 new features\r[AutoFeat]    17/   22 new features\r[AutoFeat]    18/   22 new features\r[AutoFeat]    19/   22 new features\r[AutoFeat]    20/   22 new features\r[AutoFeat]    21/   22 new features\r[AutoFeat]    22/   22 new features ...done.\n## Final R^2: 0.9693\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["#feature selector for di\nfsel_di = FeatureSelector(verbose=1,\n                          keep = feat_keep,\n                          n_jobs=6)\n\n#crete DF with selected features for di\ndi_FE_cyc_agg_DF = fsel_di.fit_transform(new_df_di, Y_di)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[featsel] Scaling data...done.\n[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\nPickling array (shape=(80,), dtype=object).\nMemmapping (shape=(80, 8288), dtype=float32) to new file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-28b28bfbed424d8e96c5842d374095b7.pkl\nPickling array (shape=(80,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(80,), dtype=object).\nMemmapping (shape=(80, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-28b28bfbed424d8e96c5842d374095b7.pkl\nPickling array (shape=(80,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(80,), dtype=object).\nMemmapping (shape=(80, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-28b28bfbed424d8e96c5842d374095b7.pkl\nPickling array (shape=(80,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(80,), dtype=object).\nMemmapping (shape=(80, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-28b28bfbed424d8e96c5842d374095b7.pkl\nPickling array (shape=(80,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(80,), dtype=object).\nMemmapping (shape=(80, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-28b28bfbed424d8e96c5842d374095b7.pkl\nPickling array (shape=(80,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\n[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   11.0s\n[Parallel(n_jobs=6)]: Done   2 out of   5 | elapsed:   11.3s remaining:   16.9s\n[Parallel(n_jobs=6)]: Done   3 out of   5 | elapsed:   11.8s remaining:    7.9s\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:   13.7s remaining:    0.0s\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:   13.7s finished\n[featsel] 70 features after 5 feature selection runs\n[featsel] 61 features after correlation filtering\n[featsel] 27 features after noise filtering\n[featsel] 61 final features selected (including 61 original keep features).\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["di_FE_cyc_agg_DF.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_3</th>\n      <th>cell_4</th>\n      <th>cell_5</th>\n      <th>cell_6</th>\n      <th>cell_7</th>\n      <th>cell_9</th>\n      <th>cell_10</th>\n      <th>cell_11</th>\n      <th>cell_13</th>\n      <th>cell_14</th>\n      <th>cell_18</th>\n      <th>cell_19</th>\n      <th>cell_20</th>\n      <th>cell_23</th>\n      <th>cell_24</th>\n      <th>cell_26</th>\n      <th>cell_27</th>\n      <th>cell_28</th>\n      <th>cell_29</th>\n      <th>T_b6</th>\n      <th>cycle</th>\n      <th>i0x2a</th>\n      <th>i0x8c</th>\n      <th>c_const_B_14</th>\n      <th>c_const_B_6b</th>\n      <th>cycle*sin(i0x91)</th>\n      <th>T_5a**3*cycle**2</th>\n      <th>i0x28**3*sin(i0x2a)</th>\n      <th>cycle**2*sqrt(i0x94)</th>\n      <th>i0x8c**2*(1 - i0x8c)</th>\n      <th>sqrt(i0xb1)*(1 - i0xb1)</th>\n      <th>c_const_B_b2*cos(i0x28)</th>\n      <th>c_const_T_c4**3*i0x91**3</th>\n      <th>cycle**2*exp(c_const_T_32)</th>\n      <th>i0x2</th>\n      <th>T_5a</th>\n      <th>i0x73</th>\n      <th>i0xb1</th>\n      <th>i0x83</th>\n      <th>i0x91</th>\n      <th>i0x8a</th>\n      <th>rng_ocv</th>\n      <th>i0x8c**2*(1 - T_5a)</th>\n      <th>i0x28**3*sin(i0x8a)</th>\n      <th>(1 - i0x28)*sin(i0x28)</th>\n      <th>sqrt(i0x91)*(1 - i0x91)</th>\n      <th>c_const_B_b2*rng_ocv**2</th>\n      <th>sqrt(i0xa7)*exp(c_const_T_5)</th>\n      <th>sqrt(i0xa7)*cos(c_const_T_32)</th>\n      <th>i0x6</th>\n      <th>i0x28</th>\n      <th>c_const_T_c4</th>\n      <th>B_78**3*(1 - i0x28)</th>\n      <th>c_const_T_32**2*i0x2a</th>\n      <th>max_ocv</th>\n      <th>min_ocv</th>\n      <th>c_const_T_32</th>\n      <th>c_const_B_76</th>\n      <th>cycle*i0x2a**2</th>\n      <th>2**B_78*exp(T_5a)</th>\n      <th>exp(i0x2a)*exp(-i0xa7)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>4.0</td>\n      <td>0.899833</td>\n      <td>0.521605</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.684853</td>\n      <td>0.0</td>\n      <td>0.482805</td>\n      <td>0.000000</td>\n      <td>0.130158</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>26.379540</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.249766</td>\n      <td>0.653333</td>\n      <td>0.434783</td>\n      <td>0.253061</td>\n      <td>894.0</td>\n      <td>0.272072</td>\n      <td>0.154336</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>799236.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.224958</td>\n      <td>4223.0</td>\n      <td>3329.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>3.238798</td>\n      <td>2.0</td>\n      <td>2.259373</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>5.0</td>\n      <td>0.882413</td>\n      <td>0.530193</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.106066</td>\n      <td>0.0</td>\n      <td>0.476056</td>\n      <td>3.195581</td>\n      <td>0.132065</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>41.218032</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.019608</td>\n      <td>0.249766</td>\n      <td>0.655652</td>\n      <td>0.434783</td>\n      <td>0.253061</td>\n      <td>792.0</td>\n      <td>0.281105</td>\n      <td>0.154336</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>627264.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.220603</td>\n      <td>4231.0</td>\n      <td>3439.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>3.893261</td>\n      <td>2.0</td>\n      <td>2.220355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>6.0</td>\n      <td>0.374342</td>\n      <td>0.759402</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.527279</td>\n      <td>0.0</td>\n      <td>0.225405</td>\n      <td>1.972130</td>\n      <td>0.138751</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>59.353966</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.003601</td>\n      <td>0.249766</td>\n      <td>0.717538</td>\n      <td>0.434783</td>\n      <td>0.092182</td>\n      <td>801.0</td>\n      <td>0.576691</td>\n      <td>0.056744</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>641601.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.093585</td>\n      <td>4221.0</td>\n      <td>3420.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.840791</td>\n      <td>2.0</td>\n      <td>1.335888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>7.0</td>\n      <td>0.369151</td>\n      <td>0.761785</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.948493</td>\n      <td>0.0</td>\n      <td>0.222424</td>\n      <td>3.900180</td>\n      <td>0.138240</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>80.787342</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.007603</td>\n      <td>0.249766</td>\n      <td>0.718182</td>\n      <td>0.434783</td>\n      <td>0.090847</td>\n      <td>802.0</td>\n      <td>0.580316</td>\n      <td>0.055924</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>643204.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.092288</td>\n      <td>4221.0</td>\n      <td>3419.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.953905</td>\n      <td>2.0</td>\n      <td>1.328971</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>8.0</td>\n      <td>0.409185</td>\n      <td>0.743409</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.369706</td>\n      <td>0.0</td>\n      <td>0.245255</td>\n      <td>7.298339</td>\n      <td>0.141807</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>105.518161</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.015606</td>\n      <td>0.249766</td>\n      <td>0.713220</td>\n      <td>0.434783</td>\n      <td>0.101141</td>\n      <td>798.0</td>\n      <td>0.552656</td>\n      <td>0.062241</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>636804.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.102296</td>\n      <td>4220.0</td>\n      <td>3422.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.339458</td>\n      <td>2.0</td>\n      <td>1.383254</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["#add 'cell_no', 'protcol', 'di', 'ocv' back to the data\ninfo = cyc_agg_DF.toPandas()\ninfo = info[['cell_no', 'protocol', 'cycle', 'di', 'dur_by_ocv']]\ndi_FE_cyc_agg_DF = pd.concat([info, di_FE_cyc_agg_DF], axis = 1)\n\n#this df has 'cycle' column two times, remove the duplicate column\ndi_FE_cyc_agg_DF = di_FE_cyc_agg_DF.loc[:,~di_FE_cyc_agg_DF.columns.duplicated()]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["#df with engineered features\ndi_FE_cyc_agg_DF.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_no</th>\n      <th>protocol</th>\n      <th>cycle</th>\n      <th>di</th>\n      <th>dur_by_ocv</th>\n      <th>cell_3</th>\n      <th>cell_4</th>\n      <th>cell_5</th>\n      <th>cell_6</th>\n      <th>cell_7</th>\n      <th>cell_9</th>\n      <th>cell_10</th>\n      <th>cell_11</th>\n      <th>cell_13</th>\n      <th>cell_14</th>\n      <th>cell_18</th>\n      <th>cell_19</th>\n      <th>cell_20</th>\n      <th>cell_23</th>\n      <th>cell_24</th>\n      <th>cell_26</th>\n      <th>cell_27</th>\n      <th>cell_28</th>\n      <th>cell_29</th>\n      <th>T_b6</th>\n      <th>i0x2a</th>\n      <th>i0x8c</th>\n      <th>c_const_B_14</th>\n      <th>c_const_B_6b</th>\n      <th>cycle*sin(i0x91)</th>\n      <th>T_5a**3*cycle**2</th>\n      <th>i0x28**3*sin(i0x2a)</th>\n      <th>cycle**2*sqrt(i0x94)</th>\n      <th>i0x8c**2*(1 - i0x8c)</th>\n      <th>sqrt(i0xb1)*(1 - i0xb1)</th>\n      <th>c_const_B_b2*cos(i0x28)</th>\n      <th>c_const_T_c4**3*i0x91**3</th>\n      <th>cycle**2*exp(c_const_T_32)</th>\n      <th>i0x2</th>\n      <th>T_5a</th>\n      <th>i0x73</th>\n      <th>i0xb1</th>\n      <th>i0x83</th>\n      <th>i0x91</th>\n      <th>i0x8a</th>\n      <th>rng_ocv</th>\n      <th>i0x8c**2*(1 - T_5a)</th>\n      <th>i0x28**3*sin(i0x8a)</th>\n      <th>(1 - i0x28)*sin(i0x28)</th>\n      <th>sqrt(i0x91)*(1 - i0x91)</th>\n      <th>c_const_B_b2*rng_ocv**2</th>\n      <th>sqrt(i0xa7)*exp(c_const_T_5)</th>\n      <th>sqrt(i0xa7)*cos(c_const_T_32)</th>\n      <th>i0x6</th>\n      <th>i0x28</th>\n      <th>c_const_T_c4</th>\n      <th>B_78**3*(1 - i0x28)</th>\n      <th>c_const_T_32**2*i0x2a</th>\n      <th>max_ocv</th>\n      <th>min_ocv</th>\n      <th>c_const_T_32</th>\n      <th>c_const_B_76</th>\n      <th>cycle*i0x2a**2</th>\n      <th>2**B_78*exp(T_5a)</th>\n      <th>exp(i0x2a)*exp(-i0xa7)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>4</td>\n      <td>0.858171</td>\n      <td>2.583579</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.899833</td>\n      <td>0.521605</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.684853</td>\n      <td>0.0</td>\n      <td>0.482805</td>\n      <td>0.000000</td>\n      <td>0.130158</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>26.379540</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.249766</td>\n      <td>0.653333</td>\n      <td>0.434783</td>\n      <td>0.253061</td>\n      <td>894.0</td>\n      <td>0.272072</td>\n      <td>0.154336</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>799236.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.224958</td>\n      <td>4223.0</td>\n      <td>3329.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>3.238798</td>\n      <td>2.0</td>\n      <td>2.259373</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>5</td>\n      <td>0.837832</td>\n      <td>2.456929</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.882413</td>\n      <td>0.530193</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.106066</td>\n      <td>0.0</td>\n      <td>0.476056</td>\n      <td>3.195581</td>\n      <td>0.132065</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>41.218032</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.019608</td>\n      <td>0.249766</td>\n      <td>0.655652</td>\n      <td>0.434783</td>\n      <td>0.253061</td>\n      <td>792.0</td>\n      <td>0.281105</td>\n      <td>0.154336</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>627264.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.220603</td>\n      <td>4231.0</td>\n      <td>3439.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>3.893261</td>\n      <td>2.0</td>\n      <td>2.220355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>6</td>\n      <td>0.695297</td>\n      <td>2.940633</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.374342</td>\n      <td>0.759402</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.527279</td>\n      <td>0.0</td>\n      <td>0.225405</td>\n      <td>1.972130</td>\n      <td>0.138751</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>59.353966</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.003601</td>\n      <td>0.249766</td>\n      <td>0.717538</td>\n      <td>0.434783</td>\n      <td>0.092182</td>\n      <td>801.0</td>\n      <td>0.576691</td>\n      <td>0.056744</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>641601.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.093585</td>\n      <td>4221.0</td>\n      <td>3420.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.840791</td>\n      <td>2.0</td>\n      <td>1.335888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>7</td>\n      <td>0.693164</td>\n      <td>2.945015</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.369151</td>\n      <td>0.761785</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.948493</td>\n      <td>0.0</td>\n      <td>0.222424</td>\n      <td>3.900180</td>\n      <td>0.138240</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>80.787342</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.007603</td>\n      <td>0.249766</td>\n      <td>0.718182</td>\n      <td>0.434783</td>\n      <td>0.090847</td>\n      <td>802.0</td>\n      <td>0.580316</td>\n      <td>0.055924</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>643204.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.092288</td>\n      <td>4221.0</td>\n      <td>3419.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.953905</td>\n      <td>2.0</td>\n      <td>1.328971</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>8</td>\n      <td>0.702145</td>\n      <td>2.903154</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.409185</td>\n      <td>0.743409</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.369706</td>\n      <td>0.0</td>\n      <td>0.245255</td>\n      <td>7.298339</td>\n      <td>0.141807</td>\n      <td>0.374941</td>\n      <td>0.659184</td>\n      <td>0.0</td>\n      <td>105.518161</td>\n      <td>0.599933</td>\n      <td>0.0</td>\n      <td>0.015606</td>\n      <td>0.249766</td>\n      <td>0.713220</td>\n      <td>0.434783</td>\n      <td>0.101141</td>\n      <td>798.0</td>\n      <td>0.552656</td>\n      <td>0.062241</td>\n      <td>0.111997</td>\n      <td>0.372693</td>\n      <td>636804.0</td>\n      <td>0.291111</td>\n      <td>0.255474</td>\n      <td>1.0</td>\n      <td>0.851064</td>\n      <td>0.0</td>\n      <td>0.148936</td>\n      <td>0.102296</td>\n      <td>4220.0</td>\n      <td>3422.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.339458</td>\n      <td>2.0</td>\n      <td>1.383254</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["di_df = spark.createDataFrame(di_FE_cyc_agg_DF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["#write the di_FE_cyc_agg_DF as csv file to use later \n\ndi_df.coalesce(1) \\\n.orderBy(\"cell_no\",\"protocol\", \"cycle\") \\\n.write.format(\"com.databricks.spark.csv\") \\\n.option(\"header\", \"true\") \\\n.save(\"/FileStore/tables/dir_di_FE_cyc_agg_DF.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["#create the autofeat model for regression\naf_regr_dur_by_ocv = AutoFeatRegressor(feateng_cols = feat_use, \n                               feateng_steps= 2,\n                               transformations=(\"1/\", \"exp\", \"log\", \"abs\", \"sqrt\", \"^2\", \"^3\", \"1+\", \"1-\", \"sin\", \"cos\", \"exp-\", \"2^\"),\n                               verbose=1,\n                               n_jobs=6)\n\n#fit and transform X to obtain engineered features for dur_by_ocv\nnew_df_dur_by_ocv = af_regr_dur_by_ocv.fit_transform(X, Y_dur_by_ocv)\nr2_dur_by_ocv = af_regr_dur_by_ocv.score(X, Y_dur_by_ocv)\nprint(\"## Final R^2: %.4f\" % r2_dur_by_ocv)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[AutoFeat] The 2 step feature engineering process could generate up to 128778 features.\n[AutoFeat] With 8288 data points this new feature matrix would use about 4.27 gb of space.\n[feateng] Step 1: transformation of original features\n[feateng]               0/             39 features transformed\r[feateng] Generated 224 transformed features from 39 original features - done.\n[feateng] Step 2: first combination of features\n[feateng]               0/          34453 feature tuples combined\r[feateng]             100/          34453 feature tuples combined\r[feateng]             200/          34453 feature tuples combined\r[feateng]             300/          34453 feature tuples combined\r[feateng]             400/          34453 feature tuples combined\r[feateng]             500/          34453 feature tuples combined\r[feateng]             600/          34453 feature tuples combined\r[feateng]             700/          34453 feature tuples combined\r[feateng]             800/          34453 feature tuples combined\r[feateng]             900/          34453 feature tuples combined\r[feateng]            1000/          34453 feature tuples combined\r[feateng]            1100/          34453 feature tuples combined\r[feateng]            1200/          34453 feature tuples combined\r[feateng]            1300/          34453 feature tuples combined\r[feateng]            1400/          34453 feature tuples combined\r[feateng]            1500/          34453 feature tuples combined\r[feateng]            1600/          34453 feature tuples combined\r[feateng]            1700/          34453 feature tuples combined\r[feateng]            1800/          34453 feature tuples combined\r[feateng]            1900/          34453 feature tuples combined\r[feateng]            2000/          34453 feature tuples combined\r[feateng]            2100/          34453 feature tuples combined\r[feateng]            2200/          34453 feature tuples combined\r[feateng]            2300/          34453 feature tuples combined\r[feateng]            2400/          34453 feature tuples combined\r[feateng]            2500/          34453 feature tuples combined\r[feateng]            2600/          34453 feature tuples combined\r[feateng]            2700/          34453 feature tuples combined\r[feateng]            2800/          34453 feature tuples combined\r[feateng]            2900/          34453 feature tuples combined\r[feateng]            3000/          34453 feature tuples combined\r[feateng]            3100/          34453 feature tuples combined\r[feateng]            3200/          34453 feature tuples combined\r[feateng]            3300/          34453 feature tuples combined\r[feateng]            3400/          34453 feature tuples combined\r[feateng]            3500/          34453 feature tuples combined\r[feateng]            3600/          34453 feature tuples combined\r[feateng]            3700/          34453 feature tuples combined\r[feateng]            3800/          34453 feature tuples combined\r[feateng]            3900/          34453 feature tuples combined\r[feateng]            4000/          34453 feature tuples combined\r[feateng]            4100/          34453 feature tuples combined\r[feateng]            4200/          34453 feature tuples combined\r[feateng]            4300/          34453 feature tuples combined\r[feateng]            4400/          34453 feature tuples combined\r[feateng]            4500/          34453 feature tuples combined\r[feateng]            4600/          34453 feature tuples combined\r[feateng]            4700/          34453 feature tuples combined\r[feateng]            4800/          34453 feature tuples combined\r[feateng]            4900/          34453 feature tuples combined\r[feateng]            5000/          34453 feature tuples combined\r[feateng]            5100/          34453 feature tuples combined\r[feateng]            5200/          34453 feature tuples combined\r[feateng]            5300/          34453 feature tuples combined\r[feateng]            5400/          34453 feature tuples combined\r[feateng]            5500/          34453 feature tuples combined\r[feateng]            5600/          34453 feature tuples combined\r[feateng]            5700/          34453 feature tuples combined\r[feateng]            5800/          34453 feature tuples combined\r[feateng]            5900/          34453 feature tuples combined\r[feateng]            6000/          34453 feature tuples combined\r[feateng]            6100/          34453 feature tuples combined\r[feateng]            6200/          34453 feature tuples combined\r[feateng]            6300/          34453 feature tuples combined\r[feateng]            6400/          34453 feature tuples combined\r[feateng]            6500/          34453 feature tuples combined\r[feateng]            6600/          34453 feature tuples combined\r[feateng]            6700/          34453 feature tuples combined\r[feateng]            6800/          34453 feature tuples combined\r[feateng]            6900/          34453 feature tuples combined\r[feateng]            7000/          34453 feature tuples combined\r[feateng]            7100/          34453 feature tuples combined\r[feateng]            7200/          34453 feature tuples combined\r[feateng]            7300/          34453 feature tuples combined\r[feateng]            7400/          34453 feature tuples combined\r[feateng]            7500/          34453 feature tuples combined\r[feateng]            7600/          34453 feature tuples combined\r[feateng]            7700/          34453 feature tuples combined\r[feateng]            7800/          34453 feature tuples combined\r[feateng]            7900/          34453 feature tuples combined\r[feateng]            8000/          34453 feature tuples combined\r[feateng]            8100/          34453 feature tuples combined\r[feateng]            8200/          34453 feature tuples combined\r[feateng]            8300/          34453 feature tuples combined\r[feateng]            8400/          34453 feature tuples combined\r[feateng]            8500/          34453 feature tuples combined\r[feateng]            8600/          34453 feature tuples combined\r[feateng]            8700/          34453 feature tuples combined\r[feateng]            8800/          34453 feature tuples combined\r[feateng]            8900/          34453 feature tuples combined\r[feateng]            9000/          34453 feature tuples combined\r[feateng]            9100/          34453 feature tuples combined\r[feateng]            9200/          34453 feature tuples combined\r[feateng]            9300/          34453 feature tuples combined\r[feateng]            9400/          34453 feature tuples combined\r[feateng]            9500/          34453 feature tuples combined\r[feateng]            9600/          34453 feature tuples combined\r[feateng]            9700/          34453 feature tuples combined\r[feateng]            9800/          34453 feature tuples combined\r[feateng]            9900/          34453 feature tuples combined\r[feateng]           10000/          34453 feature tuples combined\r[feateng]           10100/          34453 feature tuples combined\r[feateng]           10200/          34453 feature tuples combined\r[feateng]           10300/          34453 feature tuples combined\r/databricks/python/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n  x = um.multiply(x, x, out=x)\n/databricks/python/lib/python3.7/site-packages/numpy/core/_methods.py:199: RuntimeWarning: overflow encountered in reduce\n  ret = umr_sum(x, axis, dtype, out, keepdims)\n[feateng]           10400/          34453 feature tuples combined\r[feateng]           10500/          34453 feature tuples combined\r[feateng]           10600/          34453 feature tuples combined\r[feateng]           10700/          34453 feature tuples combined\r[feateng]           10800/          34453 feature tuples combined\r[feateng]           10900/          34453 feature tuples combined\r[feateng]           11000/          34453 feature tuples combined\r[feateng]           11100/          34453 feature tuples combined\r[feateng]           11200/          34453 feature tuples combined\r[feateng]           11300/          34453 feature tuples combined\r[feateng]           11400/          34453 feature tuples combined\r[feateng]           11500/          34453 feature tuples combined\r[feateng]           11600/          34453 feature tuples combined\r[feateng]           11700/          34453 feature tuples combined\r[feateng]           11800/          34453 feature tuples combined\r[feateng]           11900/          34453 feature tuples combined\r[feateng]           12000/          34453 feature tuples combined\r[feateng]           12100/          34453 feature tuples combined\r[feateng]           12200/          34453 feature tuples combined\r[feateng]           12300/          34453 feature tuples combined\r[feateng]           12400/          34453 feature tuples combined\r[feateng]           12500/          34453 feature tuples combined\r[feateng]           12600/          34453 feature tuples combined\r[feateng]           12700/          34453 feature tuples combined\r[feateng]           12800/          34453 feature tuples combined\r[feateng]           12900/          34453 feature tuples combined\r[feateng]           13000/          34453 feature tuples combined\r[feateng]           13100/          34453 feature tuples combined\r[feateng]           13200/          34453 feature tuples combined\r[feateng]           13300/          34453 feature tuples combined\r[feateng]           13400/          34453 feature tuples combined\r[feateng]           13500/          34453 feature tuples combined\r[feateng]           13600/          34453 feature tuples combined\r[feateng]           13700/          34453 feature tuples combined\r[feateng]           13800/          34453 feature tuples combined\r[feateng]           13900/          34453 feature tuples combined\r[feateng]           14000/          34453 feature tuples combined\r[feateng]           14100/          34453 feature tuples combined\r[feateng]           14200/          34453 feature tuples combined\r[feateng]           14300/          34453 feature tuples combined\r[feateng]           14400/          34453 feature tuples combined\r[feateng]           14500/          34453 feature tuples combined\r[feateng]           14600/          34453 feature tuples combined\r[feateng]           14700/          34453 feature tuples combined\r[feateng]           14800/          34453 feature tuples combined\r[feateng]           14900/          34453 feature tuples combined\r[feateng]           15000/          34453 feature tuples combined\r[feateng]           15100/          34453 feature tuples combined\r[feateng]           15200/          34453 feature tuples combined\r[feateng]           15300/          34453 feature tuples combined\r[feateng]           15400/          34453 feature tuples combined\r[feateng]           15500/          34453 feature tuples combined\r[feateng]           15600/          34453 feature tuples combined\r[feateng]           15700/          34453 feature tuples combined\r[feateng]           15800/          34453 feature tuples combined\r[feateng]           15900/          34453 feature tuples combined\r[feateng]           16000/          34453 feature tuples combined\r[feateng]           16100/          34453 feature tuples combined\r[feateng]           16200/          34453 feature tuples combined\r[feateng]           16300/          34453 feature tuples combined\r[feateng]           16400/          34453 feature tuples combined\r[feateng]           16500/          34453 feature tuples combined\r[feateng]           16600/          34453 feature tuples combined\r[feateng]           16700/          34453 feature tuples combined\r[feateng]           16800/          34453 feature tuples combined\r[feateng]           16900/          34453 feature tuples combined\r[feateng]           17000/          34453 feature tuples combined\r[feateng]           17100/          34453 feature tuples combined\r[feateng]           17200/          34453 feature tuples combined\r[feateng]           17300/          34453 feature tuples combined\r[feateng]           17400/          34453 feature tuples combined\r[feateng]           17500/          34453 feature tuples combined\r[feateng]           17600/          34453 feature tuples combined\r[feateng]           17700/          34453 feature tuples combined\r[feateng]           17800/          34453 feature tuples combined\r[feateng]           17900/          34453 feature tuples combined\r[feateng]           18000/          34453 feature tuples combined\r[feateng]           18100/          34453 feature tuples combined\r[feateng]           18200/          34453 feature tuples combined\r[feateng]           18300/          34453 feature tuples combined\r[feateng]           18400/          34453 feature tuples combined\r[feateng]           18500/          34453 feature tuples combined\r[feateng]           18600/          34453 feature tuples combined\r[feateng]           18700/          34453 feature tuples combined\r[feateng]           18800/          34453 feature tuples combined\r[feateng]           18900/          34453 feature tuples combined\r[feateng]           19000/          34453 feature tuples combined\r[feateng]           19100/          34453 feature tuples combined\r[feateng]           19200/          34453 feature tuples combined\r[feateng]           19300/          34453 feature tuples combined\r[feateng]           19400/          34453 feature tuples combined\r[feateng]           19500/          34453 feature tuples combined\r[feateng]           19600/          34453 feature tuples combined\r[feateng]           19700/          34453 feature tuples combined\r[feateng]           19800/          34453 feature tuples combined\r[feateng]           19900/          34453 feature tuples combined\r[feateng]           20000/          34453 feature tuples combined\r[feateng]           20100/          34453 feature tuples combined\r[feateng]           20200/          34453 feature tuples combined\r[feateng]           20300/          34453 feature tuples combined\r[feateng]           20400/          34453 feature tuples combined\r[feateng]           20500/          34453 feature tuples combined\r[feateng]           20600/          34453 feature tuples combined\r[feateng]           20700/          34453 feature tuples combined\r[feateng]           20800/          34453 feature tuples combined\r[feateng]           20900/          34453 feature tuples combined\r[feateng]           21000/          34453 feature tuples combined\r[feateng]           21100/          34453 feature tuples combined\r[feateng]           21200/          34453 feature tuples combined\r[feateng]           21300/          34453 feature tuples combined\r[feateng]           21400/          34453 feature tuples combined\r[feateng]           21500/          34453 feature tuples combined\r[feateng]           21600/          34453 feature tuples combined\r[feateng]           21700/          34453 feature tuples combined\r[feateng]           21800/          34453 feature tuples combined\r[feateng]           21900/          34453 feature tuples combined\r[feateng]           22000/          34453 feature tuples combined\r[feateng]           22100/          34453 feature tuples combined\r[feateng]           22200/          34453 feature tuples combined\r[feateng]           22300/          34453 feature tuples combined\r[feateng]           22400/          34453 feature tuples combined\r[feateng]           22500/          34453 feature tuples combined\r[feateng]           22600/          34453 feature tuples combined\r[feateng]           22700/          34453 feature tuples combined\r[feateng]           22800/          34453 feature tuples combined\r[feateng]           22900/          34453 feature tuples combined\r[feateng]           23000/          34453 feature tuples combined\r[feateng]           23100/          34453 feature tuples combined\r[feateng]           23200/          34453 feature tuples combined\r[feateng]           23300/          34453 feature tuples combined\r[feateng]           23400/          34453 feature tuples combined\r[feateng]           23500/          34453 feature tuples combined\r[feateng]           23600/          34453 feature tuples combined\r[feateng]           23700/          34453 feature tuples combined\r[feateng]           23800/          34453 feature tuples combined\r[feateng]           23900/          34453 feature tuples combined\r[feateng]           24000/          34453 feature tuples combined\r[feateng]           24100/          34453 feature tuples combined\r[feateng]           24200/          34453 feature tuples combined\r[feateng]           24300/          34453 feature tuples combined\r[feateng]           24400/          34453 feature tuples combined\r[feateng]           24500/          34453 feature tuples combined\r[feateng]           24600/          34453 feature tuples combined\r[feateng]           24700/          34453 feature tuples combined\r[feateng]           24800/          34453 feature tuples combined\r[feateng]           24900/          34453 feature tuples combined\r[feateng]           25000/          34453 feature tuples combined\r[feateng]           25100/          34453 feature tuples combined\r[feateng]           25200/          34453 feature tuples combined\r[feateng]           25300/          34453 feature tuples combined\r[feateng]           25400/          34453 feature tuples combined\r[feateng]           25500/          34453 feature tuples combined\r[feateng]           25600/          34453 feature tuples combined\r[feateng]           25700/          34453 feature tuples combined\r[feateng]           25800/          34453 feature tuples combined\r[feateng]           25900/          34453 feature tuples combined\r[feateng]           26000/          34453 feature tuples combined\r[feateng]           26100/          34453 feature tuples combined\r[feateng]           26200/          34453 feature tuples combined\r[feateng]           26300/          34453 feature tuples combined\r[feateng]           26400/          34453 feature tuples combined\r[feateng]           26500/          34453 feature tuples combined\r[feateng]           26600/          34453 feature tuples combined\r[feateng]           26700/          34453 feature tuples combined\r[feateng]           26800/          34453 feature tuples combined\r[feateng]           26900/          34453 feature tuples combined\r[feateng]           27000/          34453 feature tuples combined\r[feateng]           27100/          34453 feature tuples combined\r[feateng]           27200/          34453 feature tuples combined\r[feateng]           27300/          34453 feature tuples combined\r[feateng]           27400/          34453 feature tuples combined\r[feateng]           27500/          34453 feature tuples combined\r[feateng]           27600/          34453 feature tuples combined\r[feateng]           27700/          34453 feature tuples combined\r[feateng]           27800/          34453 feature tuples combined\r[feateng]           27900/          34453 feature tuples combined\r[feateng]           28000/          34453 feature tuples combined\r[feateng]           28100/          34453 feature tuples combined\r[feateng]           28200/          34453 feature tuples combined\r[feateng]           28300/          34453 feature tuples combined\r[feateng]           28400/          34453 feature tuples combined\r[feateng]           28500/          34453 feature tuples combined\r[feateng]           28600/          34453 feature tuples combined\r[feateng]           28700/          34453 feature tuples combined\r[feateng]           28800/          34453 feature tuples combined\r[feateng]           28900/          34453 feature tuples combined\r[feateng]           29000/          34453 feature tuples combined\r[feateng]           29100/          34453 feature tuples combined\r[feateng]           29200/          34453 feature tuples combined\r[feateng]           29300/          34453 feature tuples combined\r[feateng]           29400/          34453 feature tuples combined\r[feateng]           29500/          34453 feature tuples combined\r[feateng]           29600/          34453 feature tuples combined\r[feateng]           29700/          34453 feature tuples combined\r[feateng]           29800/          34453 feature tuples combined\r[feateng]           29900/          34453 feature tuples combined\r[feateng]           30000/          34453 feature tuples combined\r[feateng]           30100/          34453 feature tuples combined\r[feateng]           30200/          34453 feature tuples combined\r[feateng]           30300/          34453 feature tuples combined\r[feateng]           30400/          34453 feature tuples combined\r[feateng]           30500/          34453 feature tuples combined\r[feateng]           30600/          34453 feature tuples combined\r[feateng]           30700/          34453 feature tuples combined\r[feateng]           30800/          34453 feature tuples combined\r[feateng]           30900/          34453 feature tuples combined\r[feateng]           31000/          34453 feature tuples combined\r[feateng]           31100/          34453 feature tuples combined\r[feateng]           31200/          34453 feature tuples combined\r[feateng]           31300/          34453 feature tuples combined\r[feateng]           31400/          34453 feature tuples combined\r[feateng]           31500/          34453 feature tuples combined\r[feateng]           31600/          34453 feature tuples combined\r[feateng]           31700/          34453 feature tuples combined\r[feateng]           31800/          34453 feature tuples combined\r[feateng]           31900/          34453 feature tuples combined\r[feateng]           32000/          34453 feature tuples combined\r[feateng]           32100/          34453 feature tuples combined\r[feateng]           32200/          34453 feature tuples combined\r[feateng]           32300/          34453 feature tuples combined\r[feateng]           32400/          34453 feature tuples combined\r[feateng]           32500/          34453 feature tuples combined\r[feateng]           32600/          34453 feature tuples combined\r[feateng]           32700/          34453 feature tuples combined\r[feateng]           32800/          34453 feature tuples combined\r[feateng]           32900/          34453 feature tuples combined\r[feateng]           33000/          34453 feature tuples combined\r[feateng]           33100/          34453 feature tuples combined\r[feateng]           33200/          34453 feature tuples combined\r[feateng]           33300/          34453 feature tuples combined\r[feateng]           33400/          34453 feature tuples combined\r[feateng]           33500/          34453 feature tuples combined\r[feateng]           33600/          34453 feature tuples combined\r[feateng]           33700/          34453 feature tuples combined\r[feateng]           33800/          34453 feature tuples combined\r[feateng]           33900/          34453 feature tuples combined\r[feateng]           34000/          34453 feature tuples combined\r[feateng]           34100/          34453 feature tuples combined\r[feateng]           34200/          34453 feature tuples combined\r[feateng]           34300/          34453 feature tuples combined\r[feateng]           34400/          34453 feature tuples combined\r[feateng] Generated 33689 feature combinations from 34453 original feature tuples - done.\n[feateng] Generated altogether 34642 new features in 2 steps\n[feateng] Removing correlated features, as well as additions at the highest level\n/databricks/python/lib/python3.7/site-packages/sympy/__init__.py:676: SymPyDeprecationWarning: \n\nimporting sympy.core.add with &#39;from sympy import *&#39; has been\ndeprecated since SymPy 1.6. Use import sympy.core.add instead. See\nhttps://github.com/sympy/sympy/issues/18245 for more info.\n\n  deprecated_since_version=&#34;1.6&#34;).warn()\n[feateng] Generated a total of 12831 additional features\n[featsel] Scaling data...done.\n[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to new file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-56a3268564c54024bbf9ec6f4755fa8e.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-56a3268564c54024bbf9ec6f4755fa8e.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-56a3268564c54024bbf9ec6f4755fa8e.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-56a3268564c54024bbf9ec6f4755fa8e.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(9291,), dtype=object).\nMemmapping (shape=(9291, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-56a3268564c54024bbf9ec6f4755fa8e.pkl\nPickling array (shape=(9291,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\n[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed: 42.7min\n[Parallel(n_jobs=6)]: Done   2 out of   5 | elapsed: 48.4min remaining: 72.6min\n[Parallel(n_jobs=6)]: Done   3 out of   5 | elapsed: 49.4min remaining: 32.9min\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed: 52.2min remaining:    0.0s\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed: 52.2min finished\n[featsel] 109 features after 5 feature selection runs\n[featsel] 76 features after correlation filtering\n[featsel] 35 features after noise filtering\n[AutoFeat] Computing 32 new features.\n[AutoFeat]     0/   32 new features\r[AutoFeat]     1/   32 new features\r[AutoFeat]     2/   32 new features\r[AutoFeat]     3/   32 new features\r[AutoFeat]     4/   32 new features\r[AutoFeat]     5/   32 new features\r[AutoFeat]     6/   32 new features\r[AutoFeat]     7/   32 new features\r[AutoFeat]     8/   32 new features\r[AutoFeat]     9/   32 new features\r[AutoFeat]    10/   32 new features\r[AutoFeat]    11/   32 new features\r[AutoFeat]    12/   32 new features\r[AutoFeat]    13/   32 new features\r[AutoFeat]    14/   32 new features\r[AutoFeat]    15/   32 new features\r[AutoFeat]    16/   32 new features\r[AutoFeat]    17/   32 new features\r[AutoFeat]    18/   32 new features\r[AutoFeat]    19/   32 new features\r[AutoFeat]    20/   32 new features\r[AutoFeat]    21/   32 new features\r[AutoFeat]    22/   32 new features\r[AutoFeat]    23/   32 new features\r[AutoFeat]    24/   32 new features\r[AutoFeat]    25/   32 new features\r[AutoFeat]    26/   32 new features\r[AutoFeat]    27/   32 new features\r[AutoFeat]    28/   32 new features\r[AutoFeat]    29/   32 new features\r[AutoFeat]    30/   32 new features\r[AutoFeat]    31/   32 new features\r[AutoFeat]    32/   32 new features ...done.\n[AutoFeat] Final dataframe with 90 feature columns (32 new).\n[AutoFeat] Training final regression model.\n[AutoFeat] Trained model: largest coefficients:\n-4.574562345374238\n-111.292374 * (1 - i0xcd)/rng_ocv\n-18.433042 * i0x2a**2*sin(i0xcd)\n6.835526 * log(rng_ocv)/rng_ocv\n-3.298566 * sqrt(i0x91)*(1 - i0x91)\n-2.962471 * i0x8c**2*(1 - i0x8c)\n-2.664000 * i0x28**3*sin(i0x8a)\n2.574142 * sqrt(i0xcd)*sin(c_const_T_5)\n-2.394754 * sqrt(i0xb1)*(1 - i0xb1)\n1.847022 * c_const_B_c9*(1 - i0x28)\n1.638562 * (1 - i0x28)*sin(i0x28)\n1.202525 * c_const_B_6b*sqrt(c_const_T_5)\n1.047848 * cell_9\n-0.898939 * i0xa7**3*(1 - i0x28)\n0.815974 * cell_10\n-0.666166 * c_const_B_9*sqrt(i0x91)\n-0.656378 * sqrt(i0x8a)*exp(i0x94)\n-0.649975 * exp(c_const_T_c4)*sin(i0x91)\n-0.644501 * (1 - i0x8c)*exp(-B_78)\n-0.392680 * P_const_2c/cycle\n-0.302427 * P_const_2c*c_const_B_3b\n0.251613 * P_const_30*cos(max_ocv)\n-0.145248 * c_const_B_76*(1 - c_const_T_5)\n-0.114188 * c_const_B_29*cos(max_ocv)\n-0.063671 * c_const_T_32**2/cycle\n0.032617 * cell_4\n-0.028629 * c_const_B_76*exp(-c_const_T_c4)\n0.022073 * sqrt(max_ocv)*log(min_ocv)\n0.000521 * c_const_B_6b*cycle\n[AutoFeat] Final score: 0.9428\n[AutoFeat] Computing 32 new features.\n[AutoFeat]     0/   32 new features\r[AutoFeat]     1/   32 new features\r[AutoFeat]     2/   32 new features\r[AutoFeat]     3/   32 new features\r[AutoFeat]     4/   32 new features\r[AutoFeat]     5/   32 new features\r[AutoFeat]     6/   32 new features\r[AutoFeat]     7/   32 new features\r[AutoFeat]     8/   32 new features\r[AutoFeat]     9/   32 new features\r[AutoFeat]    10/   32 new features\r[AutoFeat]    11/   32 new features\r[AutoFeat]    12/   32 new features\r[AutoFeat]    13/   32 new features\r[AutoFeat]    14/   32 new features\r[AutoFeat]    15/   32 new features\r[AutoFeat]    16/   32 new features\r[AutoFeat]    17/   32 new features\r[AutoFeat]    18/   32 new features\r[AutoFeat]    19/   32 new features\r[AutoFeat]    20/   32 new features\r[AutoFeat]    21/   32 new features\r[AutoFeat]    22/   32 new features\r[AutoFeat]    23/   32 new features\r[AutoFeat]    24/   32 new features\r[AutoFeat]    25/   32 new features\r[AutoFeat]    26/   32 new features\r[AutoFeat]    27/   32 new features\r[AutoFeat]    28/   32 new features\r[AutoFeat]    29/   32 new features\r[AutoFeat]    30/   32 new features\r[AutoFeat]    31/   32 new features\r[AutoFeat]    32/   32 new features ...done.\n## Final R^2: 0.9428\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["#feature selector for dur_by_ocv\nfsel_dur_by_ocv = FeatureSelector(verbose=1,\n                          keep = feat_keep,\n                          n_jobs=6)\n\n#crete DF with selected features for dur_by_ocv\ndur_by_ocv_FE_cyc_agg_DF = fsel_dur_by_ocv.fit_transform(new_df_dur_by_ocv, Y_dur_by_ocv)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[featsel] Scaling data...done.\n[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\nPickling array (shape=(90,), dtype=object).\nMemmapping (shape=(90, 8288), dtype=float32) to new file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-00ed4f96a2f14121bdd0a855df9af3ba.pkl\nPickling array (shape=(90,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(90,), dtype=object).\nMemmapping (shape=(90, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-00ed4f96a2f14121bdd0a855df9af3ba.pkl\nPickling array (shape=(90,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(90,), dtype=object).\nMemmapping (shape=(90, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-00ed4f96a2f14121bdd0a855df9af3ba.pkl\nPickling array (shape=(90,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(90,), dtype=object).\nMemmapping (shape=(90, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-00ed4f96a2f14121bdd0a855df9af3ba.pkl\nPickling array (shape=(90,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\nPickling array (shape=(90,), dtype=object).\nMemmapping (shape=(90, 8288), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6002_1711667118/6002-139901624198160-00ed4f96a2f14121bdd0a855df9af3ba.pkl\nPickling array (shape=(90,), dtype=object).\nPickling array (shape=(8288,), dtype=float64).\n[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   11.8s\n[Parallel(n_jobs=6)]: Done   2 out of   5 | elapsed:   11.9s remaining:   17.8s\n[Parallel(n_jobs=6)]: Done   3 out of   5 | elapsed:   11.9s remaining:    8.0s\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:   13.2s remaining:    0.0s\n[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:   13.2s finished\n[featsel] 66 features after 5 feature selection runs\n[featsel] 64 features after correlation filtering\n[featsel] 35 features after noise filtering\n[featsel] 64 final features selected (including 64 original keep features).\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["#add 'cell_no', 'protcol', 'di', 'ocv' back\ninfo = cyc_agg_DF.toPandas()\ninfo = info[['cell_no', 'protocol', 'cycle', 'di', 'dur_by_ocv']]\ndur_by_ocv_FE_cyc_agg_DF = pd.concat([info, dur_by_ocv_FE_cyc_agg_DF], axis = 1)\n\n#this df has 'cycle' column two times, remove the duplicate column\ndur_by_ocv_FE_cyc_agg_DF = dur_by_ocv_FE_cyc_agg_DF.loc[:,~dur_by_ocv_FE_cyc_agg_DF.columns.duplicated()]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["dur_by_ocv_FE_cyc_agg_DF.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_no</th>\n      <th>protocol</th>\n      <th>cycle</th>\n      <th>di</th>\n      <th>dur_by_ocv</th>\n      <th>cell_3</th>\n      <th>cell_4</th>\n      <th>cell_5</th>\n      <th>cell_6</th>\n      <th>cell_7</th>\n      <th>cell_9</th>\n      <th>cell_10</th>\n      <th>cell_11</th>\n      <th>cell_13</th>\n      <th>cell_14</th>\n      <th>cell_18</th>\n      <th>cell_19</th>\n      <th>cell_20</th>\n      <th>cell_23</th>\n      <th>cell_24</th>\n      <th>cell_26</th>\n      <th>cell_27</th>\n      <th>cell_28</th>\n      <th>cell_29</th>\n      <th>i0x6</th>\n      <th>i0xb1</th>\n      <th>i0x83</th>\n      <th>i0x2a</th>\n      <th>i0x28</th>\n      <th>i0x91</th>\n      <th>i0x8c</th>\n      <th>max_ocv</th>\n      <th>rng_ocv</th>\n      <th>P_const_2c</th>\n      <th>c_const_B_9</th>\n      <th>c_const_T_32</th>\n      <th>c_const_B_b2</th>\n      <th>P_const_2c/cycle</th>\n      <th>c_const_B_6b*cycle</th>\n      <th>min_ocv**3*rng_ocv</th>\n      <th>(1 - i0xcd)/rng_ocv</th>\n      <th>i0x2a**2*sin(i0xcd)</th>\n      <th>cycle**3*sin(i0xcd)</th>\n      <th>sqrt(i0x8a)/rng_ocv</th>\n      <th>i0xa7**3*(1 - i0x28)</th>\n      <th>min_ocv**3*cos(i0xa7)</th>\n      <th>rng_ocv**3*sin(i0xb1)</th>\n      <th>(1 - i0x8c)*exp(-B_78)</th>\n      <th>(1 - i0x28)*sin(i0x28)</th>\n      <th>P_const_2c*c_const_B_3b</th>\n      <th>sqrt(i0x91)*(1 - i0x91)</th>\n      <th>P_const_30*cos(max_ocv)</th>\n      <th>sqrt(i0xb1)*(1 - i0xb1)</th>\n      <th>c_const_B_c9*(1 - i0x28)</th>\n      <th>c_const_B_29*cos(max_ocv)</th>\n      <th>sqrt(i0xcd)*sin(c_const_T_5)</th>\n      <th>exp(c_const_T_c4)*sin(i0x91)</th>\n      <th>rng_ocv**3*exp(-c_const_T_32)</th>\n      <th>i0x8a</th>\n      <th>i0x94</th>\n      <th>i0x28**3*sin(i0x8a)</th>\n      <th>sqrt(i0x8a)*exp(i0x94)</th>\n      <th>c_const_B_6b*sqrt(c_const_T_5)</th>\n      <th>c_const_B_76*exp(-c_const_T_c4)</th>\n      <th>log(rng_ocv)/rng_ocv</th>\n      <th>c_const_T_32**2/cycle</th>\n      <th>c_const_B_9*sqrt(i0x91)</th>\n      <th>c_const_B_6b*rng_ocv**3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>4</td>\n      <td>0.858171</td>\n      <td>2.583579</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.249766</td>\n      <td>0.653333</td>\n      <td>0.899833</td>\n      <td>0.851064</td>\n      <td>0.434783</td>\n      <td>0.521605</td>\n      <td>4223.0</td>\n      <td>894.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3.298215e+13</td>\n      <td>0.001119</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000563</td>\n      <td>0.000091</td>\n      <td>3.676038e+10</td>\n      <td>1.766120e+08</td>\n      <td>0.175992</td>\n      <td>0.111997</td>\n      <td>0.0</td>\n      <td>0.372693</td>\n      <td>0.0</td>\n      <td>0.374941</td>\n      <td>0.148936</td>\n      <td>0.765181</td>\n      <td>0.0</td>\n      <td>0.421213</td>\n      <td>4.333765e+08</td>\n      <td>0.253061</td>\n      <td>0.000000</td>\n      <td>0.154336</td>\n      <td>0.503052</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.007601</td>\n      <td>0.062500</td>\n      <td>0.0</td>\n      <td>714516984.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>5</td>\n      <td>0.837832</td>\n      <td>2.456929</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.249766</td>\n      <td>0.655652</td>\n      <td>0.882413</td>\n      <td>0.851064</td>\n      <td>0.434783</td>\n      <td>0.530193</td>\n      <td>4231.0</td>\n      <td>792.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>3.221230e+13</td>\n      <td>0.001232</td>\n      <td>0.019085</td>\n      <td>3.063725</td>\n      <td>0.000635</td>\n      <td>0.000091</td>\n      <td>4.052613e+10</td>\n      <td>1.227957e+08</td>\n      <td>0.172832</td>\n      <td>0.111997</td>\n      <td>0.0</td>\n      <td>0.372693</td>\n      <td>-0.0</td>\n      <td>0.374941</td>\n      <td>0.148936</td>\n      <td>-0.748298</td>\n      <td>0.0</td>\n      <td>0.421213</td>\n      <td>3.013202e+08</td>\n      <td>0.253061</td>\n      <td>0.016339</td>\n      <td>0.154336</td>\n      <td>0.511339</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.008427</td>\n      <td>0.050000</td>\n      <td>0.0</td>\n      <td>496793088.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>6</td>\n      <td>0.695297</td>\n      <td>2.940633</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.249766</td>\n      <td>0.717538</td>\n      <td>0.374342</td>\n      <td>0.851064</td>\n      <td>0.434783</td>\n      <td>0.759402</td>\n      <td>4221.0</td>\n      <td>801.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>3.204135e+13</td>\n      <td>0.001243</td>\n      <td>0.000631</td>\n      <td>0.972483</td>\n      <td>0.000379</td>\n      <td>0.000091</td>\n      <td>3.985813e+10</td>\n      <td>1.270297e+08</td>\n      <td>0.088511</td>\n      <td>0.111997</td>\n      <td>0.0</td>\n      <td>0.372693</td>\n      <td>0.0</td>\n      <td>0.374941</td>\n      <td>0.148936</td>\n      <td>0.266992</td>\n      <td>0.0</td>\n      <td>0.421213</td>\n      <td>3.117097e+08</td>\n      <td>0.092182</td>\n      <td>0.003001</td>\n      <td>0.056744</td>\n      <td>0.304528</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.008347</td>\n      <td>0.041667</td>\n      <td>0.0</td>\n      <td>513922401.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>7</td>\n      <td>0.693164</td>\n      <td>2.945015</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.249766</td>\n      <td>0.718182</td>\n      <td>0.369151</td>\n      <td>0.851064</td>\n      <td>0.434783</td>\n      <td>0.761785</td>\n      <td>4221.0</td>\n      <td>802.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.205322e+13</td>\n      <td>0.001235</td>\n      <td>0.001295</td>\n      <td>3.260081</td>\n      <td>0.000376</td>\n      <td>0.000091</td>\n      <td>3.982318e+10</td>\n      <td>1.275061e+08</td>\n      <td>0.087635</td>\n      <td>0.111997</td>\n      <td>0.0</td>\n      <td>0.372693</td>\n      <td>0.0</td>\n      <td>0.374941</td>\n      <td>0.148936</td>\n      <td>0.266992</td>\n      <td>0.0</td>\n      <td>0.421213</td>\n      <td>3.128786e+08</td>\n      <td>0.090847</td>\n      <td>0.006335</td>\n      <td>0.055924</td>\n      <td>0.303324</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.008338</td>\n      <td>0.035714</td>\n      <td>0.0</td>\n      <td>515849608.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>140f77741820c02177597651dfea9fe881c1a73d8e4002...</td>\n      <td>8</td>\n      <td>0.702145</td>\n      <td>2.903154</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.249766</td>\n      <td>0.713220</td>\n      <td>0.409185</td>\n      <td>0.851064</td>\n      <td>0.434783</td>\n      <td>0.743409</td>\n      <td>4220.0</td>\n      <td>798.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>3.197738e+13</td>\n      <td>0.001229</td>\n      <td>0.003266</td>\n      <td>9.988361</td>\n      <td>0.000399</td>\n      <td>0.000091</td>\n      <td>3.992810e+10</td>\n      <td>1.256077e+08</td>\n      <td>0.094395</td>\n      <td>0.111997</td>\n      <td>0.0</td>\n      <td>0.372693</td>\n      <td>-0.0</td>\n      <td>0.374941</td>\n      <td>0.148936</td>\n      <td>-0.666668</td>\n      <td>0.0</td>\n      <td>0.421213</td>\n      <td>3.082204e+08</td>\n      <td>0.101141</td>\n      <td>0.013004</td>\n      <td>0.062241</td>\n      <td>0.322190</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.008374</td>\n      <td>0.031250</td>\n      <td>0.0</td>\n      <td>508169592.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["dur_by_ocv_df = spark.createDataFrame(dur_by_ocv_FE_cyc_agg_DF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["#write the di_FE_cyc_agg_DF as csv file to use later \n\ndur_by_ocv_df.coalesce(1) \\\n.orderBy(\"cell_no\",\"protocol\", \"cycle\") \\\n.write.format(\"com.databricks.spark.csv\") \\\n.option(\"header\", \"true\") \\\n.save(\"/FileStore/tables/dir_dur_by_ocv_FE_cyc_agg_DF.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20}],"metadata":{"name":"04_Auto Feature Engineering & Selection","notebookId":2218950630433282},"nbformat":4,"nbformat_minor":0}
